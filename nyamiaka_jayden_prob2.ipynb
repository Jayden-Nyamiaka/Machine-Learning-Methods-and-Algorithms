{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayden-Nyamiaka/Machine-Learning-and-Data-Mining/blob/main/nyamiaka_jayden_prob2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fzZb8grE78U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvPFMow_NNry"
      },
      "source": [
        "# Part A: Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m_kQfspQJNf"
      },
      "outputs": [],
      "source": [
        "# Loads COVID Data\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/emiletimothy/Caltech-CS155-2023/main/set4/data/COVID-19_Case_Surveillance_Public_Use_Data_Subset.csv\")\n",
        "df.rename(columns={\"Unnamed: 0\":\"bias\", \"cdc_case_earliest_dt \":\"cdc_case_earliest_dt\"}, inplace=True)\n",
        "df[\"bias\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESSES DATASET\n",
        "\n",
        "# Helper function to find the percent that a value appears in a column\n",
        "def appearancePercent(dataframe, column, value):\n",
        "  return (dataframe[column]==value).sum() / len(df) * 100\n",
        "\n",
        "# Helper function to remove any rows where the value at the indicated \n",
        "# column equals one of the values provided in the values list\n",
        "def removeUnavailable(dataframe, column, values):\n",
        "  total_percent = 0\n",
        "  for value in values:\n",
        "    total_percent += appearancePercent(dataframe, column, value)\n",
        "  print(\"Dropped Rows with\", column, \"=\", values, \":\", total_percent, \"%\")\n",
        "  for value in values:\n",
        "    dataframe.drop(dataframe.loc[df[column]==value].index, inplace=True)\n",
        "  print()\n",
        "\n",
        "# Helper function to normalize a feature column using mean and stddev\n",
        "def normalize_column(dataframe, column):\n",
        "  dataframe[column] = (dataframe[column] - dataframe[column].mean()) / dataframe[column].std() \n",
        "\n",
        "# Print Number of Data Points before Preprocessing\n",
        "print(\"Number of Data Points Before Preprocessing:\", len(df), \"points\")\n",
        "print(\"Number of Features Before Preprocessing (Not including death_yn or bias):\", len(df.columns) - 2, \"features\")\n",
        "print()\n",
        "\n",
        "# Finds and drop any duplicates in the dataset, if there are any\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Finds and drops the columns with unavailable values (the three dates)\n",
        "print(\"Percent of Unavailable Values per Input Variable: \")\n",
        "print(df.isna().sum()/len(df)*100)\n",
        "df.dropna(axis=1,inplace=True)\n",
        "print()\n",
        "\n",
        "# Drops rows with missing and unknown death info\n",
        "removeUnavailable(df, \"death_yn\", [\"Unknown\", \"Missing\"])\n",
        "\n",
        "# Drops racial identity column (shouldn't be considered for moral reasons)\n",
        "df.drop(\"race_ethnicity_combined\", axis=1, inplace=True)\n",
        "\n",
        "# Transforms string dates for cdc_case_earliest_dt into numerical time stamps\n",
        "def time_str_to_numerical(time_str):\n",
        "  return datetime.timestamp(datetime.strptime(time_str, \"%Y/%m/%d\"))\n",
        "df[\"cdc_case_earliest_dt\"] = df[\"cdc_case_earliest_dt\"].apply(time_str_to_numerical)\n",
        "\n",
        "# Finds and removes rows with Unknown, Missing, Other, or NA sex values\n",
        "# Note: There are so little points without sex set that we can just remove them\n",
        "removeUnavailable(df, \"sex\", [\"Unknown\", \"Missing\", \"Other\", \"NA\"])\n",
        "\n",
        "# Sets current status and sex to boolean (1, 0) values\n",
        "df[\"current_status\"].replace({\"Laboratory-confirmed case\": 1, \"Probable Case\": 0}, inplace=True)\n",
        "df[\"sex\"].replace({\"Male\": 1, \"Female\": 0}, inplace=True)\n",
        "\n",
        "# Uses one hot encoding for hosp_yn, icu_yn, and medcond_yn \n",
        "df[\"hosp_yn\"].replace({\"No\": \"no_hosp\", \"Unknown\": \"hosp_unknown\", \"Missing\": \"hosp_unknown\", \"Yes\": \"hosp\"}, inplace=True)\n",
        "df[\"icu_yn\"].replace({\"No\": \"no_icu\", \"Unknown\": \"icu_unknown\", \"Missing\": \"icu_unknown\", \"Yes\": \"icu\"}, inplace=True)\n",
        "df[\"medcond_yn\"].replace({\"No\": \"no_medcond\", \"Unknown\": \"medcond_unknown\", \"Missing\": \"medcond_unknown\", \"Yes\": \"medcond\"}, inplace=True)\n",
        "df = df.join(pd.get_dummies(df[\"hosp_yn\"]))\n",
        "df = df.join(pd.get_dummies(df[\"icu_yn\"]))\n",
        "df = df.join(pd.get_dummies(df[\"medcond_yn\"]))\n",
        "df.drop([\"hosp_yn\", \"icu_yn\", \"medcond_yn\", \"hosp_unknown\", \"icu_unknown\", \"medcond_unknown\"], axis=1, inplace=True)\n",
        "\n",
        "# Finds and removes rows with Missing or NA age_group values\n",
        "# Note: There are so little points without age group set that we can just remove them\n",
        "removeUnavailable(df, \"age_group\", [\"Missing\", \"NA\"])\n",
        "\n",
        "# Enumerates age_group values starting at 0\n",
        "df[\"age_group\"].replace({\"0 - 9 Years\": 0, \n",
        "                         \"10 - 19 Years\": 1,\n",
        "                         \"20 - 29 Years\": 2,\n",
        "                         \"30 - 39 Years\": 3,\n",
        "                         \"40 - 49 Years\": 4,\n",
        "                         \"50 - 59 Years\": 5,\n",
        "                         \"60 - 69 Years\": 6,\n",
        "                         \"70 - 79 Years\": 7,\n",
        "                         \"80+ Years\": 8}, inplace=True)\n",
        "\n",
        "# Sets death info to boolean (1, 0) values\n",
        "df[\"death_yn\"].replace({\"Yes\": 1, \"No\": 0}, inplace=True)\n",
        "\n",
        "# Moves death_yn labels to the last column\n",
        "death_labels = df[\"death_yn\"]\n",
        "df.drop(\"death_yn\", axis=1, inplace=True)\n",
        "df[\"death_yn\"] = death_labels\n",
        "\n",
        "# Normalizes cdc_case_earliest_dt and age_group features using mean and stddev\n",
        "for column in df.columns:\n",
        "  if column == \"bias\" or column == \"death_yn\":\n",
        "    continue\n",
        "  normalize_column(df, column)\n",
        "print(\"Normalized All Columns of Data\")\n",
        "print()\n",
        "\n",
        "print(\"Number of Data Points After Preprocessing:\", len(df), \"points\")\n",
        "print(\"Number of Features After Preprocessing (Not including death_yn or bias):\", len(df.columns) - 2, \"features\")\n",
        "display(df.head(12))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "6vqcoqwl6pcL",
        "outputId": "13e3677b-7812-4a92-a83b-616bc470dc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Data Points Before Preprocessing: 800000 points\n",
            "Number of Features Before Preprocessing (Not including death_yn or bias): 11 features\n",
            "\n",
            "Percent of Unavailable Values per Input Variable: \n",
            "bias                        0.000000\n",
            "cdc_case_earliest_dt        0.000000\n",
            "cdc_report_dt               5.696436\n",
            "pos_spec_dt                48.831920\n",
            "onset_dt                   53.871555\n",
            "current_status              0.000000\n",
            "sex                         0.000000\n",
            "age_group                   0.000000\n",
            "race_ethnicity_combined     0.000000\n",
            "hosp_yn                     0.000000\n",
            "icu_yn                      0.000000\n",
            "death_yn                    0.000000\n",
            "medcond_yn                  0.000000\n",
            "dtype: float64\n",
            "\n",
            "Dropped Rows with death_yn = ['Unknown', 'Missing'] : 61.67776358281605 %\n",
            "\n",
            "Dropped Rows with sex = ['Unknown', 'Missing', 'Other', 'NA'] : 1.7555048942445133 %\n",
            "\n",
            "Dropped Rows with age_group = ['Missing', 'NA'] : 0.0 %\n",
            "\n",
            "Normalized All Columns of Data\n",
            "\n",
            "Number of Data Points After Preprocessing: 217195 points\n",
            "Number of Features After Preprocessing (Not including death_yn or bias): 10 features\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    bias  cdc_case_earliest_dt  current_status       sex  age_group      hosp  \\\n",
              "0      1             -1.396417        0.458860  1.030078   0.711241 -0.244811   \n",
              "1      1              1.950307       -2.179306  1.030078   1.643255 -0.244811   \n",
              "5      1              0.638103        0.458860 -0.970796  -1.152787 -0.244811   \n",
              "6      1             -1.191761        0.458860  1.030078  -1.152787 -0.244811   \n",
              "8      1             -1.007169        0.458860 -0.970796  -0.686780 -0.244811   \n",
              "9      1              0.465550        0.458860  1.030078  -1.152787 -0.244811   \n",
              "12     1             -0.509575        0.458860 -0.970796   0.711241 -0.244811   \n",
              "13     1              0.682244        0.458860  1.030078   0.245234 -0.244811   \n",
              "14     1             -0.999144        0.458860  1.030078  -0.220773 -0.244811   \n",
              "15     1              0.822694        0.458860 -0.970796   0.711241 -0.244811   \n",
              "18     1              0.670205        0.458860  1.030078   0.245234 -0.244811   \n",
              "23     1              1.163787        0.458860  1.030078  -0.220773 -0.244811   \n",
              "\n",
              "     no_hosp       icu    no_icu  medcond  no_medcond  death_yn  \n",
              "0   0.768307 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "1  -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "5   0.768307 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "6   0.768307 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "8   0.768307 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "9  -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "12  0.768307 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "13 -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "14 -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "15 -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "18 -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  \n",
              "23 -1.301557 -0.073181 -0.297453  -0.2786   -0.352003         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9041ea4a-f574-4781-b081-e10f776c587b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bias</th>\n",
              "      <th>cdc_case_earliest_dt</th>\n",
              "      <th>current_status</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_group</th>\n",
              "      <th>hosp</th>\n",
              "      <th>no_hosp</th>\n",
              "      <th>icu</th>\n",
              "      <th>no_icu</th>\n",
              "      <th>medcond</th>\n",
              "      <th>no_medcond</th>\n",
              "      <th>death_yn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.396417</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>0.711241</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>0.768307</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.950307</td>\n",
              "      <td>-2.179306</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>1.643255</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0.638103</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>-0.970796</td>\n",
              "      <td>-1.152787</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>0.768307</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.191761</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>-1.152787</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>0.768307</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.007169</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>-0.970796</td>\n",
              "      <td>-0.686780</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>0.768307</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0.465550</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>-1.152787</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.509575</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>-0.970796</td>\n",
              "      <td>0.711241</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>0.768307</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>0.682244</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>0.245234</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.999144</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>-0.220773</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>0.822694</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>-0.970796</td>\n",
              "      <td>0.711241</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>0.670205</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>0.245234</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>1.163787</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>1.030078</td>\n",
              "      <td>-0.220773</td>\n",
              "      <td>-0.244811</td>\n",
              "      <td>-1.301557</td>\n",
              "      <td>-0.073181</td>\n",
              "      <td>-0.297453</td>\n",
              "      <td>-0.2786</td>\n",
              "      <td>-0.352003</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9041ea4a-f574-4781-b081-e10f776c587b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9041ea4a-f574-4781-b081-e10f776c587b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9041ea4a-f574-4781-b081-e10f776c587b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wn-AQp6FDpM"
      },
      "outputs": [],
      "source": [
        "# Split training and test data 70:30\n",
        "split_index_7030 = int(len(df) * 0.7)\n",
        "num_features = len(df.columns) - 1\n",
        "training_data = df.iloc[:split_index_7030, :]\n",
        "test_data = df.iloc[split_index_7030:, :]\n",
        "\n",
        "train_X = torch.tensor(training_data.drop(\"death_yn\", axis=1).values.astype(np.float32))\n",
        "train_y = torch.tensor(training_data[\"death_yn\"].values.astype(np.int_))\n",
        "\n",
        "test_X = torch.tensor(test_data.drop(\"death_yn\", axis=1).values.astype(np.float32))\n",
        "test_y = torch.tensor(test_data[\"death_yn\"].values.astype(np.int_))\n",
        "\n",
        "# Make datasets and dataloaders\n",
        "train_dataset = TensorDataset(train_X, train_y)\n",
        "test_dataset = TensorDataset(test_X, test_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ccx89l3btfq4"
      },
      "source": [
        "# Part B: Linear Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aICcIvNtNGk2"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtMSBKxdFfjq"
      },
      "outputs": [],
      "source": [
        "# Makes your model, optmizer, and loss function here.\n",
        "size = 5\n",
        "learning_rate = 1e-3\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(num_features, size),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(size, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training and Testing Helper Functions"
      ],
      "metadata": {
        "id": "z8dqV56jJpD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Trains the model, printing the loss at every epoch as a decimal\n",
        "def train_model(model, epochs, train_loader, optimizer, loss_fn):\n",
        "  # Some layers, such as Dropout, behave differently during training\n",
        "  epochs = 8\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for batch_idx, (data, target) in enumerate(train_loader):\n",
        "          # Erase accumulated gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "\n",
        "          # Calculate loss\n",
        "          loss = loss_fn(output, target)\n",
        "\n",
        "          # Backward pass\n",
        "          loss.backward()\n",
        "          \n",
        "          # Weight update\n",
        "          optimizer.step()\n",
        "\n",
        "      # Track loss each epoch\n",
        "      print('Train Epoch: %d  Loss: %.4f' % (epoch + 1,  loss.item()))\n",
        "\n",
        "\n",
        "# Tests the model, printing the average loss and accuracy\n",
        "def test_model(model, test_loader, loss_fn):\n",
        "  # Putting layers like Dropout into evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  # Turning off automatic differentiation\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_loader:\n",
        "          output = model(data)\n",
        "          test_loss += loss_fn(output, target).item()  # Sum up batch loss\n",
        "          pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max class score\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('Test set: Average loss: %.4f, Accuracy: %d/%d (%.4f)' %\n",
        "        (test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "1xf0TMFsJsyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKl5Tm2TNXxc"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-RVMsj0NaN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aec7b71-ef79-483a-a085-afc314184b7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1  Loss: 0.3133\n",
            "Train Epoch: 2  Loss: 0.3133\n",
            "Train Epoch: 3  Loss: 0.3142\n",
            "Train Epoch: 4  Loss: 0.3134\n",
            "Train Epoch: 5  Loss: 0.3133\n",
            "Train Epoch: 6  Loss: 0.3133\n",
            "Train Epoch: 7  Loss: 0.3133\n",
            "Train Epoch: 8  Loss: 0.3137\n"
          ]
        }
      ],
      "source": [
        "epochs = 8\n",
        "train_model(model, epochs, train_loader, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZCNGh5mNbE0"
      },
      "source": [
        "## Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SxnJ3eHNfgb",
        "outputId": "2ffb3679-b05d-433c-f5bb-88cbd0ee4c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set: Average loss: 0.0107, Accuracy: 63252/65159 (97.0733)\n"
          ]
        }
      ],
      "source": [
        "test_model(model, test_loader, loss_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf9UHC-kZ25f"
      },
      "source": [
        "## Weight Matrix Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBXDC10mRNto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3d05a820-7fd0-40dc-de9d-a1eb291c0e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f139e9cbc70>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWwAAAD4CAYAAADIH9xYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXyUlEQVR4nO3df7DddX3n8efLQPipEIzGNMEQhqwVdCZoJtMuLi0/YmPbSegu2NhpjS5snK7YWqddQ5nRLVt2Y39I29F2pAEbqxI11nJXoxgBuzOLYIIGAkGaEJAkDUQBAQ0E7r2v/eN8Ayd3773nnJzv9+Z+v/f1yHzmfH++P59zb+77fu7n+/mer2wTERGT3yuOdgMiIqI7SdgRETWRhB0RURNJ2BERNZGEHRFRE8dUXcGLP95V6TSUZy9/b5Xh2XLn7ErjA0yj2pk6/3nwgUrj/82xb6o0PsB55+6tNP6me+ZWGv+Cs6ptP8DdD1b7f3XeSc9WGh/gTbu+qn5j9JJzjp15Zt/1TaT0sCMiaqLyHnZExIQaHjraLahMEnZENMvQ4NFuQWWSsCOiUezho92EyiRhR0SzDCdhR0TUQ3rYERE1kYuOERE1kR52REQ9OLNEIiJqIhcdIyJqIkMiERE1kYuOERE1kR52RERN5KJjRERN5KJjREQ92BnDjoioh4xhR0TURIZEIiJqIj3siIiaGHrxaLegMh0TtqSfB5YDc4pNe4EB29U+2TUi4kg0eEhk3IfwSvowsB4Q8N2iCLhJ0upxzlslaYukLWs/c1OZ7Y2IGJ+Huy8106mHfTlwju3D/saQ9HHgfmDNaCfZvh64Hnp75HxERN8a3MPulLCHgZ8Dfjhi++xiX0TE5DKFE/YHgVsl7QB2F9teD5wFXFllwyIijoRLvOgoaSnw18A0YK3tNSP2XwdcUKyeCLzW9qnFviFgW7HvUdvL+m3PuAnb9jck/TtgMYdfdNzsJt9OFBH1VdLYtKRpwCeBJcAeYLOkAdvbX6rK/oO24z8AnNsW4jnbC0tpTKHjLBG3nhl/Z5mVRkRUprwhkcXATtu7ACStpzVjbvsYx78L+GhZlY9m3FkiERG108MskfYZbUVZ1RZpDi8PBUOrlz2HUUiaB8wHbmvbfHwR805Jl5Tx1nLjTEQ0Sw897PYZbX1aAWwYMVQ8z/ZeSWcCt0naZvuhfipJDzsimqW8edh7gdPb1ucW20azAjjsphPbe4vXXcC3OXx8+4gkYUdEswwOdl/GtxlYIGm+pOm0kvLAyIOKu8FnAN9p2zZD0nHF8kzgPMYe++5ahkQiollKmiVie1DSlcAttKb13Wj7fknXAFtsH0reK4D1tttvEnwj8ClJw7Q6xmvaZ5ccqSTsiGiWEm+csb0R2Dhi20dGrP/3Uc67A3hzaQ0pJGFHRLPU8DNCupWEHRHNMoVvTY+IqJf0sCMiaqLz7I/aSsKOiGZxcz/ROQk7IpolY9gRETWRhB0RURO56BgRURNDzf2o/soT9vBTj1Uaf+hApeF5/SnPVFsB8OjTr6o0/s9efL7S+I+eWP1H0ix+tto6np6mSuP/88NzuWzh7s4H9uGgqn0Pr5n3bKXxS5MhkYjoR9XJOtokYUdE1ETGsCMi6sHDmYcdEVEPGRKJiKiJzBKJiKiJ9LAjImoiCTsioiby4U8RETWRHnZERE00eFpf9fcUR0RMpKGh7ksHkpZKelDSTkmrR9n/Hkk/krS1KFe07VspaUdRVpbx1tLDjohGcUlDIpKmAZ8ElgB7gM2SBmxvH3HoF2xfOeLc04CPAosAA3cX5z7VT5vSw46IZhl292V8i4GdtnfZfgFYDyzvshW/Amyy/WSRpDcBS4/4PRWSsCOiWTzcdZG0StKWtrKqLdIcoP1Tu/YU20b6T5LulbRB0uk9ntuTDIlERLP0cNHR9vXA9X3U9r+Bm2wflPQ+YB1wYR/xxpUedkQ0y+BQ92V8e4HT29bnFtteYvsJ2weL1bXAW7s990gkYUdEs/QwJNLBZmCBpPmSpgMrgIH2AyTNbltdBjxQLN8CvF3SDEkzgLcX2/qSIZGIaJaS5mHbHpR0Ja1EOw240fb9kq4BttgeAH5P0jJgEHgSeE9x7pOS/getpA9wje0n+21TEnZENEpZ0/oAbG8ENo7Y9pG25auAq8Y490bgxtIaQxJ2RDRNg+90TMKOiGZJwo6IqIkGP8DgiGeJSHrvOPtemoy+dv3NR1pFRETPPOyuS93008P+E+DTo+1on4x+cMcd9fuqRER91TARd2vchC3p3rF2AbPKb05ERJ+m8Odhz6L1ISYjP2FKwB2VtCgioh9TtYcNfBU42fbWkTskfbuSFkVE9GOqJmzbl4+z77fKb05ERH88NHWHRCIi6mWq9rAjIuqmjtP1upWEHRHNkoQdEVETzR3CTsKOiGbxYHMzdhJ2RDRLc/N1EnZENEsuOkZE1EV62BER9ZAedkREXaSHHRFRDx482i2ozhE/wCAiYjLycPelE0lLJT0oaaek1aPs/5Ck7ZLulXSrpHlt+4YkbS3KQBnvLT3siGiWkoZEJE0DPgksAfYAmyUN2N7edtj3gUW2D0j6XeDPgN8s9j1ne2E5rWlJDzsiGqXEHvZiYKftXbZfANYDyw+ry77d9oFi9U5gbtnvp10SdkQ0Si8Ju/35s0VZ1RZqDrC7bX1PsW0slwNfb1s/voh5p6RLynhvlQ+JnHTOZZXG//PXXVBp/FdNwBXnc6Yd6HxQH3Z/4cpK4+/43U2VxgdYt3u8n5P+XfrKH1Ua/zP3nF5pfIC3TftZpfG/vLP69/BfS4jhIXV/bNvzZ/sh6beBRcAvtW2eZ3uvpDOB2yRts/1QP/VkDDsiGqWbi4ld2gu0/5aaW2w7jKSLgauBX7J98KV22HuL113FE7rOBfpK2BkSiYhG8bC6Lh1sBhZImi9pOrACOGy2h6RzgU8By2zvb9s+Q9JxxfJM4Dyg/WLlEUkPOyIapawetu1BSVcCtwDTgBtt3y/pGmCL7QHgz4GTgS9JAnjU9jLgjcCnJA3T6hivGTG75IgkYUdEo9jdj2F3juWNwMYR2z7StnzxGOfdAby5tIYUkrAjolFKHMOedJKwI6JRhnuYJVI3SdgR0ShdXEysrSTsiGiUJOyIiJpwcz8OOwk7IpolPeyIiJooc1rfZJOEHRGNMpRZIhER9ZAedkRETWQMOyKiJjJLJCKiJtLDjoioiaHh5n5qdBJ2RDRKhkQiImpiOLNEIiLqocnT+joO9kj6eUkXSTp5xPal1TUrIuLI2N2Xuhk3YUv6PeBm4APAfZKWt+3+n+Oc99Kj44eHq32Sc0REu2Gr61I3nYZE/gvwVts/lXQGsEHSGbb/Ghjz3bY/Ov6Y6XNq+HssIupqKs8SeYXtnwLYfkTSL9NK2vMYJ2FHRBwtTe4hdvpV9LikhYdWiuT968BMKnjAZEREv8ocEpG0VNKDknZKWj3K/uMkfaHYf1cxEnFo31XF9gcl/UoZ761Twn438Fj7BtuDtt8NnF9GAyIiymSr6zIeSdOATwLvAM4G3iXp7BGHXQ48Zfss4DrgY8W5ZwMrgHOApcDfFvH6Mm7Ctr3H9mNj7Pu//VYeEVG24R5KB4uBnbZ32X4BWA8sH3HMcmBdsbwBuEiSiu3rbR+0/TCws4jXl+aOzkfElGTUdelgDrC7bX1PsW3UY2wPAk8Dr+7y3J7lxpmIaJTBHqbrSVoFrGrbdH0xy21SSsKOiEbpouf88rFtU5BHsRc4vW19brFttGP2SDoGOAV4ostze5YhkYholBLHsDcDCyTNlzSd1kXEgRHHDAAri+VLgdtsu9i+ophFMh9YAHy3rzdGetgR0TC99LDHjWMPSroSuAWYBtxo+35J1wBbbA8ANwD/KGkn8CStpE5x3BeB7cAg8H7bQ/22KQk7Ihqli55z12xvBDaO2PaRtuXngcvGOPda4NoSm5OEHRHNMtTgm7CTsCOiURr8hLAk7IholuH0sCMi6qHJH/6UhB0RjVLmRcfJJgk7IhplWBkSiYiohb4nO09iSdgR0SiZJRIRUROZJdKHn27++0rjP3LZJyqNP2NO9Q8Rvm/76yqNf8aKv600/sdPWlRpfID3/eKeSuN/7TtzK43/GmDJG3Z3PK4fD2x/baXx33bC05XGL0tmiUREX6pO1vGyDIlERNREpvVFRNTEUHrYERH1kB52RERNJGFHRNRED490rJ0k7IholPSwIyJqIremR0TUROZhR0TURIZEIiJqoskJ+xVHuwEREWVyD6Ufkk6TtEnSjuJ1xijHLJT0HUn3S7pX0m+27fsHSQ9L2lqUhZ3qTMKOiEYZVvelT6uBW20vAG4t1kc6ALzb9jnAUuCvJJ3atv+PbC8sytZOFSZhR0SjDPVQ+rQcWFcsrwMuGXmA7X+1vaNY/jdgP60PbzwiSdgR0SjDuOsiaZWkLW1lVQ9VzbK9r1h+DJg13sGSFgPTgYfaNl9bDJVcJ+m4ThXmomNENEovFx1tXw9cP9Z+Sd8CRvvA+qtHxLGkMYfFJc0G/hFYaftQE6+ileinF234MHDNeO1Nwo6IRinzAQa2Lx5rn6THJc22va9IyPvHOO5VwNeAq23f2Rb7UO/8oKRPA3/YqT0ZEomIRhnuofRpAFhZLK8Ebh55gKTpwFeAz9jeMGLf7OJVtMa/7+tUYRJ2RDTKoNx16dMaYImkHcDFxTqSFklaWxzzTuB84D2jTN/7nKRtwDZgJvCnnSrMkEhENMpEPdPR9hPARaNs3wJcUSx/FvjsGOdf2GudSdgR0ShNvtOxY8IupqLY9mZJZ9Oa/P0D2xsrb11ERI+GG/zc9HHHsCV9FPgb4O8k/S/gE8BJwGpJV49z3ktzG2/Y8PVSGxwRMZ6JujX9aOjUw74UWAgcR2u+4Fzbz0j6C+Au4NrRTmqf2/j8PRvr+HWJiJqaykMig7aHgAOSHrL9DIDt5yQ1+esSETU1VMu+c3c6JewXJJ1o+wDw1kMbJZ1Cs3+RRURNNTkxdUrY59s+CNB2OyXAsbw8YTwiYtLwVO1hH0rWo2z/MfDjSloUEdGHqdzDjoiolSZP60vCjohGaW66TsKOiIYZbHDKTsKOiEaZshcdIyLqJhcdIyJqIj3siIiaSA87IqImhpwedkRELWQedkRETWQMOyKiJjKGHRFRE00eEslT0yOiUdzDv35IOk3SJkk7itcZYxw31PbE9IG27fMl3SVpp6QvSJreqc4k7IholCG769Kn1cCtthcAtxbro3nO9sKiLGvb/jHgOttnAU8Bl3eqMAk7IhplGHdd+rQcWFcsrwMu6fZESQIuBDb0cn71Y9gHf1Zp+Ne8odr4e7e9qtL4AE++otpvw0nHnlBp/Inw4k+qHZecOTRYafyKv8UAvFhx/+uVpzxfafyy9HLRUdIqYFXbpuuLZ9J2Y5btfcXyY8CsMY47XtIWYBBYY/ufgVcDP7F96D/eHmBOpwpz0TEiGqWXsen2B4aPRtK3gNeNsuvqEXEsaayK59neK+lM4DZJ24Cnu25kmyTsiGiUMmeJ2L54rH2SHpc02/Y+SbOB/WPE2Fu87pL0beBc4MvAqZKOKXrZc4G9ndqTMeyIaBTbXZc+DfDys21XAjePPEDSDEnHFcszgfOA7W5Vfjtw6Xjnj5SEHRGNMoS7Ln1aAyyRtAO4uFhH0iJJa4tj3ghskXQPrQS9xvb2Yt+HgQ9J2klrTPuGThVmSCQiGmWibpyx/QRw0SjbtwBXFMt3AG8e4/xdwOJe6kzCjohGKWGoY9JKwo6IRmnyrelJ2BHRKPm0voiImsgDDCIiaiJDIhERNZGEHRFRE5klEhFRE+lhR0TURGaJRETUxJCb+1THJOyIaJSMYUdE1ETGsCMiaiJj2BERNTGcIZGIiHpocg+75wcYSPpMFQ2JiCjDkIe7LnUzbg9b0sDITcAFkk4FsL1sjPNeehLxJ1av4vLfGPOxaBERpZrKQyJzge3AWsC0EvYi4C/HO6n9ScTPf/dLzf3qRcSkM5WHRBYBd9N6pPvTtr8NPGf7X2z/S9WNi4jo1bDddambcXvYtoeB6yR9qXh9vNM5ERFH01TuYQNge4/ty4CvA5+ttkkREUduyENdl35IOk3SJkk7itcZoxxzgaStbeV5SZcU+/5B0sNt+xZ2qrOnWSK2v2b7j3s5JyJiItnuuvRpNXCr7QXArcX6yLbcbnuh7YXAhcAB4Jtth/zRof22t3aqsOdpfRERk9kw7rr0aTmwrlheB1zS4fhLga/bPnCkFSZhR0Sj9NLDlrRK0pa2sqqHqmbZ3lcsPwbM6nD8CuCmEduulXSvpOskHdepwlxAjIhG6WX2R/sU5NFI+hbwulF2XT0ijiWNWbGk2cCbgVvaNl9FK9FPL9rwYeCa8dqbhB0RjVLmLBHbY971J+lxSbNt7ysS8v5xQr0T+IrtF9tiH+qdH5T0aeAPO7UnQyIR0SgTeGv6ALCyWF4J3DzOse9ixHBIkeSRJFrj3/d1qjAJOyIaZQJniawBlkjaAVxcrCNpkaS1hw6SdAZwOjDyZsPPSdoGbANmAn/aqcIMiUREo0zUHYy2nwAuGmX7FuCKtvVHgDmjHHdhr3UmYUdEo+QRYRERNZFHhEVE1ER62BERNVHHBxN0Kwk7Ihqljh+b2q0k7IholAyJRETURJM/DzsJOyIaJT3siIiaaPIYdk+3cU5EAVbVvY66x2/Ce8jXaHLUMRHvYSqVyfhZIr18Hu1kraPu8SeijrrHn4g68h7iMJMxYUdExCiSsCMiamIyJuwxn/5QozrqHn8i6qh7/ImoI+8hDqPiwkBERExyk7GHHRERo0jCjoioiUmVsCUtlfSgpJ2SVlcQ/0ZJ+yV1fHbaEcY/XdLtkrZLul/S75cc/3hJ35V0TxH/T8qM31bPNEnfl/TViuI/ImmbpK2StlQQ/1RJGyT9QNIDkn6xxNhvKNp9qDwj6YNlxW+r5w+K7/F9km6SdHzJ8X+/iH1/We0f7edL0mmSNknaUbzOKKOuKetoTwRvm2A/DXgIOJPWY9/vAc4uuY7zgbcA91X0HmYDbymWXwn8a5nvARBwcrF8LHAX8AsVvI8PAZ8HvlrR1+kRYGaF/5fWAVcUy9OBUyuqZxrwGDCv5LhzgIeBE4r1LwLvKTH+m2g98PVEWnc7fws4q4S4/9/PF/BnwOpieTXwsaq+71OhTKYe9mJgp+1dtl8A1gPLy6zA9v8Bniwz5oj4+2x/r1h+FniAUZ7l1kd82/5psXpsUUq9aixpLvBrwNpOx05Gkk6hlThuALD9gu2fVFTdRcBDtn9YQexjgBMkHUMrsf5bibHfCNxl+4DtQVoPh/2P/QYd4+drOa1foBSvl/Rbz1Q2mRL2HGB32/oeSkx2E614UvK5tHrBZcadJmkrsB/YZLvU+MBfAf8NqPJT4A18U9Ldksq+E24+8CPg08WwzlpJJ5VcxyErgJvKDmp7L/AXwKPAPuBp298ssYr7gP8g6dWSTgR+ldZTvaswy/a+YvkxYFZF9UwJkylhN4akk4EvAx+0/UyZsW0P2V4IzAUWS3pTWbEl/Tqw3/bdZcUcw9tsvwV4B/B+SeeXGPsYWn+W/53tc4Gf0fpTvFSSpgPLgC9VEHsGrZ7pfODngJMk/XZZ8W0/AHwM+CbwDWArMFRW/HHqNSX/RTjVTKaEvZfDf8vPLbbViqRjaSXrz9n+p6rqKf7Mvx1YWmLY84Blkh6hNSR1oaTPlhgfeKkHie39wFdoDYeVZQ+wp+0vjw20EnjZ3gF8z/bjFcS+GHjY9o9svwj8E/Dvy6zA9g2232r7fOApWtdbqvC4pNkAxev+iuqZEiZTwt4MLJA0v+i9rAAGjnKbeiJJtMZOH7D98Qriv0bSqcXyCcAS4Adlxbd9le25ts+g9fW/zXZpPTsASSdJeuWhZeDttP5EL4Xtx4Ddkt5QbLoI2F5W/DbvooLhkMKjwC9IOrH4P3URreshpZH02uL19bTGrz9fZvw2A8DKYnklcHNF9UwJk+bzsG0PSroSuIXW1fcbbd9fZh2SbgJ+GZgpaQ/wUds3lFjFecDvANuKcWaAP7a9saT4s4F1kqbR+mX7RduVTL2r0CzgK608xDHA521/o+Q6PgB8rvjFvwt4b5nBi180S4D3lRn3ENt3SdoAfA8YBL5P+bd4f1nSq4EXgfeXcWF2tJ8vYA3wRUmXAz8E3tlvPVNZbk2PiKiJyTQkEhER40jCjoioiSTsiIiaSMKOiKiJJOyIiJpIwo6IqIkk7IiImvh/bL4ALY7oBA8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "weights = model.state_dict()['0.weight']\n",
        "\n",
        "sns.heatmap(weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91H6-NUVZ8Gd"
      },
      "source": [
        "# Part C: 2-Layer Linear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUd6CAB-WebM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "37720752-76be-4148-e467-9f626d42a59b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3ef9cada3508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhidden_layer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model = nn.Sequential(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "# Trains a 2-layer model on our dataset\n",
        "\n",
        "# Makes the model, optmizer, and loss function\n",
        "size = 5\n",
        "hidden_layer_size = 8\n",
        "learning_rate = 1e-3\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(num_features, hidden_layer_size),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(hidden_layer_size, size),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(size, 2),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Trains the model\n",
        "epochs = 8\n",
        "train_model(model, epochs, train_loader, optimizer, loss_fn)\n",
        "\n",
        "# Tests the model\n",
        "test_model(model, test_loader, loss_fn)\n",
        "\n",
        "# Visualizes the weight matrix\n",
        "weights = model.state_dict()['0.weight']\n",
        "sns.heatmap(weights)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "4b5295d72cc8c3d140bbb6686d5919ce0ad0a523816efde1e1cd082b7d39dbc7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}